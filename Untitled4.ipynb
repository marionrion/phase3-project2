{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Case Study-1_Pump it up-Data Mining the Water Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanzania faces a major water crisis. Millions lack access to clean drinking water due to limited freshwater sources and malfunctioning water points. This lack of safe water has severe consequences, including health risks, decreased quality of life, and even death for children. The Tanzanian government is working to improve sanitation, but better water resource management is crucial for the country's future.\n",
    "\n",
    "### 1.1Tanzania faces a critical challenge:\n",
    "\n",
    "Millions of people lack access to safe drinking water due to malfunctioning water points. This project aims to leverage machine learning to predict the functionality of water points, helping prioritize maintenance and ensure clean water reaches communities across the country. By analyzing data on factors like pump type, installation age, location, and management practices, we can build a model to classify water points into three categories: functional, needing repair, or non-functional. This information can empower authorities to:\n",
    "\n",
    "### 1.2Target Maintenance Efforts: \n",
    "\n",
    "Prioritize repairs for water points most at risk of failure, ensuring efficient resource allocation and minimizing downtime.\n",
    "Preventative Maintenance: Identify pumps nearing the end of their lifespan or susceptible to breakdowns based on historical data, prompting proactive maintenance to avoid service disruptions.\n",
    "\n",
    "### 1.3Improve Resource Management:\n",
    "\n",
    "Gain insights into factors affecting water point functionality, informing strategies for pump selection, installation practices, and long-term management approaches.\n",
    "\n",
    "By harnessing the power of machine learning, we can move beyond reactive repairs and towards a proactive approach to ensuring clean water security for Tanzania's population. This project tackles the critical business problem of water scarcity by predicting water point functionality, ultimately contributing to improved public health and well-being."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Our project will be successful if we can accurately predict whether a water point is:\n",
    "\n",
    "a. Fully Functional: The water point is operational and delivers clean water without any current repairs needed.\n",
    "    \n",
    "b. Partially Functional (Needs Repair): The water point is currently operational, but there are potential issues requiring repairs to ensure continued functionality.\n",
    "\n",
    "c. Non-Functional: The water point is completely out of service and requires repairs to provide clean water again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages for data analysis, visualization, and machine learning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns  # For advanced data visualization\n",
    "import pandas as pd    # For data manipulation and analysis\n",
    "import numpy as np     # For numerical computations\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "from sklearn.svm import LinearSVC  # For linear support vector machines\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV  # For hyperparameter tuning\n",
    "from sklearn.pipeline import Pipeline   # For creating a pipeline of data processing and models\n",
    "from sklearn.preprocessing import StandardScaler  # For data standardization\n",
    "from sklearn.ensemble import RandomForestClassifier  # For random forest classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # For gradient boosting classification\n",
    "from datetime import datetime  \n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data set\n",
    "train = pd.read_csv('test doc.csv')\n",
    "test = pd.read_csv('test doc 2.csv')\n",
    "data = pd.read_csv('test doc 3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2/4/2013</td>\n",
       "      <td>Dmdd</td>\n",
       "      <td>1996</td>\n",
       "      <td>DMDD</td>\n",
       "      <td>35.290799</td>\n",
       "      <td>-4.059696</td>\n",
       "      <td>Dinamu Secondary School</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2/4/2013</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>1569</td>\n",
       "      <td>DWE</td>\n",
       "      <td>36.656709</td>\n",
       "      <td>-3.309214</td>\n",
       "      <td>Kimnyak</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2/1/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.767863</td>\n",
       "      <td>-5.004344</td>\n",
       "      <td>Puma Secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1/22/2013</td>\n",
       "      <td>Finn Water</td>\n",
       "      <td>267</td>\n",
       "      <td>FINN WATER</td>\n",
       "      <td>38.058046</td>\n",
       "      <td>-9.418672</td>\n",
       "      <td>Kwa Mzee Pange</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3/27/2013</td>\n",
       "      <td>Bruder</td>\n",
       "      <td>1260</td>\n",
       "      <td>BRUDER</td>\n",
       "      <td>35.006123</td>\n",
       "      <td>-10.950412</td>\n",
       "      <td>Kwa Mzee Turuka</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>monthly</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded                  funder  gps_height  \\\n",
       "0  50785         0.0      2/4/2013                    Dmdd        1996   \n",
       "1  51630         0.0      2/4/2013  Government Of Tanzania        1569   \n",
       "2  17168         0.0      2/1/2013                     NaN        1567   \n",
       "3  45559         0.0     1/22/2013              Finn Water         267   \n",
       "4  49871       500.0     3/27/2013                  Bruder        1260   \n",
       "\n",
       "    installer  longitude   latitude                 wpt_name  num_private  \\\n",
       "0        DMDD  35.290799  -4.059696  Dinamu Secondary School            0   \n",
       "1         DWE  36.656709  -3.309214                  Kimnyak            0   \n",
       "2         NaN  34.767863  -5.004344           Puma Secondary            0   \n",
       "3  FINN WATER  38.058046  -9.418672           Kwa Mzee Pange            0   \n",
       "4      BRUDER  35.006123 -10.950412          Kwa Mzee Turuka            0   \n",
       "\n",
       "   ... payment_type water_quality quality_group      quantity  quantity_group  \\\n",
       "0  ...    never pay          soft          good      seasonal        seasonal   \n",
       "1  ...    never pay          soft          good  insufficient    insufficient   \n",
       "2  ...    never pay          soft          good  insufficient    insufficient   \n",
       "3  ...      unknown          soft          good           dry             dry   \n",
       "4  ...      monthly          soft          good        enough          enough   \n",
       "\n",
       "                 source           source_type  source_class  \\\n",
       "0  rainwater harvesting  rainwater harvesting       surface   \n",
       "1                spring                spring   groundwater   \n",
       "2  rainwater harvesting  rainwater harvesting       surface   \n",
       "3          shallow well          shallow well   groundwater   \n",
       "4                spring                spring   groundwater   \n",
       "\n",
       "      waterpoint_type waterpoint_type_group  \n",
       "0               other                 other  \n",
       "1  communal standpipe    communal standpipe  \n",
       "2               other                 other  \n",
       "3               other                 other  \n",
       "4  communal standpipe    communal standpipe  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>3/14/2011</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3/6/2013</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2/25/2013</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1/28/2013</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7/13/2011</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0     3/14/2011         Roman        1390         Roman   \n",
       "1   8776         0.0      3/6/2013       Grumeti        1399       GRUMETI   \n",
       "2  34310        25.0     2/25/2013  Lottery Club         686  World vision   \n",
       "3  67743         0.0     1/28/2013        Unicef         263        UNICEF   \n",
       "4  19728         0.0     7/13/2011   Action In A           0       Artisan   \n",
       "\n",
       "   longitude   latitude              wpt_name  num_private  ... payment_type  \\\n",
       "0  34.938093  -9.856322                  none            0  ...     annually   \n",
       "1  34.698766  -2.147466              Zahanati            0  ...    never pay   \n",
       "2  37.460664  -3.821329           Kwa Mahundi            0  ...   per bucket   \n",
       "3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0  ...    never pay   \n",
       "4  31.130847  -1.825359               Shuleni            0  ...    never pay   \n",
       "\n",
       "  water_quality quality_group      quantity  quantity_group  \\\n",
       "0          soft          good        enough          enough   \n",
       "1          soft          good  insufficient    insufficient   \n",
       "2          soft          good        enough          enough   \n",
       "3          soft          good           dry             dry   \n",
       "4          soft          good      seasonal        seasonal   \n",
       "\n",
       "                 source           source_type  source_class  \\\n",
       "0                spring                spring   groundwater   \n",
       "1  rainwater harvesting  rainwater harvesting       surface   \n",
       "2                   dam                   dam       surface   \n",
       "3           machine dbh              borehole   groundwater   \n",
       "4  rainwater harvesting  rainwater harvesting       surface   \n",
       "\n",
       "               waterpoint_type waterpoint_type_group  \n",
       "0           communal standpipe    communal standpipe  \n",
       "1           communal standpipe    communal standpipe  \n",
       "2  communal standpipe multiple    communal standpipe  \n",
       "3  communal standpipe multiple    communal standpipe  \n",
       "4           communal standpipe    communal standpipe  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  69572      functional\n",
       "1   8776      functional\n",
       "2  34310      functional\n",
       "3  67743  non functional\n",
       "4  19728      functional"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.merge(data,on='id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>3/14/2011</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3/6/2013</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2/25/2013</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1/28/2013</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7/13/2011</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0     3/14/2011         Roman        1390         Roman   \n",
       "1   8776         0.0      3/6/2013       Grumeti        1399       GRUMETI   \n",
       "2  34310        25.0     2/25/2013  Lottery Club         686  World vision   \n",
       "3  67743         0.0     1/28/2013        Unicef         263        UNICEF   \n",
       "4  19728         0.0     7/13/2011   Action In A           0       Artisan   \n",
       "\n",
       "   longitude   latitude              wpt_name  num_private  ... water_quality  \\\n",
       "0  34.938093  -9.856322                  none            0  ...          soft   \n",
       "1  34.698766  -2.147466              Zahanati            0  ...          soft   \n",
       "2  37.460664  -3.821329           Kwa Mahundi            0  ...          soft   \n",
       "3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0  ...          soft   \n",
       "4  31.130847  -1.825359               Shuleni            0  ...          soft   \n",
       "\n",
       "  quality_group      quantity  quantity_group                source  \\\n",
       "0          good        enough          enough                spring   \n",
       "1          good  insufficient    insufficient  rainwater harvesting   \n",
       "2          good        enough          enough                   dam   \n",
       "3          good           dry             dry           machine dbh   \n",
       "4          good      seasonal        seasonal  rainwater harvesting   \n",
       "\n",
       "            source_type source_class              waterpoint_type  \\\n",
       "0                spring  groundwater           communal standpipe   \n",
       "1  rainwater harvesting      surface           communal standpipe   \n",
       "2                   dam      surface  communal standpipe multiple   \n",
       "3              borehole  groundwater  communal standpipe multiple   \n",
       "4  rainwater harvesting      surface           communal standpipe   \n",
       "\n",
       "  waterpoint_type_group    status_group  \n",
       "0    communal standpipe      functional  \n",
       "1    communal standpipe      functional  \n",
       "2    communal standpipe      functional  \n",
       "3    communal standpipe  non functional  \n",
       "4    communal standpipe      functional  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_data, test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0e566b70f572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Understanding the columns of the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of data points : ', df.shape[0])\n",
    "print('Number of features : ', df.shape[1])\n",
    "print('Features : ', df.columns.values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=190 #for reading all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for colum names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_value_counts(data):\n",
    "  for column in data.columns:\n",
    "    print(f'value counts for {column}')\n",
    "    print(data[column].value_counts())\n",
    "    print('------------------------------------------','\\n')\n",
    "\n",
    "check_value_counts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data doesn't have any data inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(data, columns):\n",
    "    fig, axes = plt.subplots(nrows=len(columns), ncols=1, figsize=(20,10))\n",
    "    for i, column in enumerate(columns):\n",
    "        # Use interquartile range (IQR) to find outliers for the specified column\n",
    "        q1 = data[column].quantile(0.25)\n",
    "        q3 = data[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        print(\"IQR for {} column: {}\".format(column, iqr))\n",
    "\n",
    "        # Determine the outliers based on the IQR\n",
    "        outliers = (data[column] < q1 - 1.5 * iqr) | (data[column] > q3 + 1.5 * iqr)\n",
    "        print(\"Number of outliers in {} column: {}\".format(column, outliers.sum()))\n",
    "\n",
    "        # Create a box plot to visualize the distribution of the specified column\n",
    "        sns.boxplot(data=data, x=column, ax=axes[i])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "num=df.select_dtypes('number')\n",
    "columns=num.columns\n",
    "check_outliers(df, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has outliers but we won't remove them because that information could be useful for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Univariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for all numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "sns.scatterplot(x='population', y='water_/_person', data=df)\n",
    "plt.title('Water per Person vs Population')\n",
    "plt.show()\n",
    "\n",
    "# Boxplots by category \n",
    "sns.boxplot(\n",
    "    x = \"region_code\",\n",
    "    y = \"amount_tsh\",\n",
    "    showmeans=True,  # Show mean as a horizontal line in the box\n",
    "    data=df\n",
    ")\n",
    "plt.title('Amount TSH by Region Code')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get maximum and minimum values for latitude and longitude\n",
    "BBox = ((\n",
    "    df[df['longitude']!=0].longitude.min(),\n",
    "    df.longitude.max(),      \n",
    "    df.latitude.min(),\n",
    "    df.latitude.max()\n",
    "))\n",
    "BBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a crosstab \n",
    "crosstb=pd.crosstab(df.region,df.extraction_type_class)\n",
    "\n",
    "#creating a bar plot\n",
    "plt.figure(figsize=(34,30))\n",
    "pl=crosstb.plot(kind=\"bar\",stacked=True,rot=90)\n",
    "plt.title(\"extraction mode in each region\", fontsize=30)\n",
    "plt.show(plt.figure(figsize=(4, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creating a crosstab \n",
    "crosstb=pd.crosstab(df.region,df.payment_type)\n",
    "\n",
    "#creating a bar plot\n",
    "plt.figure(figsize=(30,25))\n",
    "pl=crosstb.plot(kind=\"bar\",stacked=True,rot=90)\n",
    "plt.title(\"payment criteria per region\", fontsize=30)\n",
    "plt.show(plt.figure(figsize=(4, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter Plots:  scatter plots to explore relationships between pairs of numerical variables. Look for patterns like positive or negative correlations, linear or non-linear relationships.\n",
    "\n",
    "Boxplots by Category: boxplots of numerical variables grouped by categorical variables to see how the distribution of the numerical variable changes across categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['construction_year_category'] = le.fit_transform(df['construction_year'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding: For categorical variables with ordered levels (e.g., low, medium, high), use label encoding to convert them to numerical values (e.g., 1, 2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "df_encoded = pd.concat([df, pd.DataFrame(encoder.fit_transform(df[['region_code']]))], axis=1)\n",
    "df_encoded.drop('region_code', axis=1, inplace=True)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding: For categorical variables with unordered levels (e.g., region names), use one-hot encoding to create new binary features for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Transform categorical variables (replace with your columns)\n",
    "categorical_cols = ['construction_year', 'region_code']\n",
    "\n",
    "# Label Encoding for ordered categorical variables\n",
    "for col in categorical_cols:\n",
    "  if df[col].dtypes == 'object' and df[col].nunique() < 10:  # Check for ordered categories and less than 10 unique values\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_category'] = le.fit_transform(df[col])\n",
    "    df.drop(col, axis=1, inplace=True)  # Remove original column\n",
    "\n",
    "# One-Hot Encoding for unordered categorical variables\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "df_encoded = pd.concat([df, pd.DataFrame(encoder.fit_transform(df[categorical_cols]))], axis=1)\n",
    "df = df_encoded.copy()  # Update df with encoded data\n",
    "\n",
    "# Coding the data (your data is now ready for modeling)\n",
    "print(\"Transformed and Encoded Data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBox = ((\n",
    "    df[df['longitude']!=0].longitude.min(),\n",
    "    df.longitude.max(),      \n",
    "    df.latitude.min(),\n",
    "    df.latitude.max()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_1=df.sort_values('region',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_2=df.sort_values('management_group',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop the status-group\n",
    "\n",
    "df_status=df[['id', 'status_group']]\n",
    "df_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df\n",
    "df['water_/_person'] = df['amount_tsh'].replace({0:1}) / df['population'].replace({0:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_cardinality_check(n, df):\n",
    "\n",
    "# this function will search the dataframe for features above the cardinality limit, \n",
    "# then create a dict from the results\n",
    "\n",
    "  \n",
    "  feature_list = []\n",
    "  \n",
    "  cardinality_value = []\n",
    "  \n",
    "  for _ in range(len(df.columns)):\n",
    "    if len(df[df.columns[_]].value_counts()) > n:\n",
    "      \n",
    "      feature_list.append(df.columns[_])\n",
    "      \n",
    "      cardinality_value.append(len(df[df.columns[_]].value_counts()))\n",
    "                               \n",
    "        \n",
    "  feature_dict = dict(zip(feature_list, cardinality_value))\n",
    "  \n",
    "  return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "high_cardinality_feature_dict = reverse_cardinality_check(150, df)\n",
    "high_cardinality_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_cardinality_check(n, df):\n",
    "\n",
    "# this function will search the dataframe for features above the cardinality limit, \n",
    "# then create a dict from the results\n",
    "\n",
    "  \n",
    "  feature_list = []\n",
    "  \n",
    "  cardinality_value = []\n",
    "  \n",
    "  for _ in range(len(df.columns)):\n",
    "    if len(df[df.columns[_]].value_counts()) > n:\n",
    "      \n",
    "      feature_list.append(df.columns[_])\n",
    "      \n",
    "      cardinality_value.append(len(df[df.columns[_]].value_counts()))\n",
    "                               \n",
    "        \n",
    "  feature_dict = dict(zip(feature_list, cardinality_value))\n",
    "  \n",
    "  return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_feature_dict = reverse_cardinality_check(150, df)\n",
    "high_cardinality_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for high cardinality\n",
    "high_cardinality_features = df[list(high_cardinality_feature_dict.keys())]\n",
    "high_cardinality_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for low cardinality features\n",
    "low_cardinality_features = df.drop(columns = list(high_cardinality_feature_dict.keys()))\n",
    "low_cardinality_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the numerical columns\n",
    "one_hot_encode = ce.OneHotEncoder(use_cat_names=True)\n",
    "one_hot_encode.fit(low_cardinality_features)\n",
    "low_cardinality_features = one_hot_encode.transform(low_cardinality_features)\n",
    "\n",
    "ordinal_encode = ce.OrdinalEncoder()\n",
    "ordinal_encode.fit(high_cardinality_features)\n",
    "high_cardinality_features = ordinal_encode.transform(high_cardinality_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = low_cardinality_features.concat(high_cardinality_features,on = low_cardinality_features.index)\n",
    "frames =[low_cardinality_features, high_cardinality_features]\n",
    "\n",
    "features = pd.concat(frames, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previewing the datatset\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make our imports\n",
    "rcParams['figure.figsize'] = 30, 20\n",
    "\n",
    "# let's visualize the data\n",
    "gdf = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.longitude, df.latitude))\n",
    "\n",
    "functional = gdf.where(gdf['status_group'] == 0)\n",
    "repair = gdf.where(gdf['status_group'] == 2)\n",
    "abandoned = gdf.where(gdf['status_group'] == 1)\n",
    "broken = gdf.where(gdf['status_group'] == 3)\n",
    "\n",
    "\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# We restrict to Africa\n",
    "ax = world[world.continent == 'Africa'].plot(\n",
    "    color='gray', edgecolor='black')\n",
    "\n",
    "ax.scatter(functional['longitude'], functional['latitude'],\n",
    "           c='green',alpha=.5, s=3)\n",
    "\n",
    "ax.scatter(repair['longitude'], repair['latitude'],\n",
    "           c='blue', alpha=.5, s=5)\n",
    "\n",
    "ax.scatter(broken['longitude'], broken['latitude'],\n",
    "           c='red', alpha=.5, s=5)\n",
    "plt.title(\"Map of Pump Distributions, Green-Functional, Blue-Repair, Red-Broken\", fontsize = 25)\n",
    "\n",
    "plt.ylim(-12, 0)\n",
    "plt.xlim(28,41)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "# let's select our x and y variables\n",
    "X = df.drop('status_group', axis = 1).astype(np.float64)\n",
    "y = df['status_group']\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "# summarize distribution\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(y) * 100\n",
    "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import decision trees classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = True, random_state=0)\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "predicted_value = model.predict(X_test)\n",
    "print(predicted_value)\n",
    "#%%\n",
    "tree.plot_tree(model)\n",
    "\n",
    "zeroes = 0\n",
    "ones = 0\n",
    "for i in range(0,len(y_train)):\n",
    "    if y_train[i] == 0:\n",
    "        zeroes +=1\n",
    "    else:\n",
    "        ones +=1\n",
    "      \n",
    "print(zeroes)\n",
    "print(ones)\n",
    "\n",
    "val = 1 - ((zeroes/70)*2 + (ones/70)*2)\n",
    "print(\"Gini :-\",val)\n",
    " \n",
    "match = 0\n",
    "UnMatch = 0\n",
    " \n",
    "for i in range(30):\n",
    "    if predicted_value[i] == y_test[i]:\n",
    "        match += 1\n",
    "    else:\n",
    "        UnMatch += 1\n",
    "         \n",
    "accuracy = match/30\n",
    "print(\"Accuracy is: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG BOOST Classifier\n",
    "Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# training XGboost on the training\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "y_pred = classifier.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying K-fold cross validation \n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize domain space for range of values\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 0, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 0,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 0,10,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,10),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 100,\n",
    "        'seed': 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Objective function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"mlogloss\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization algorithm \n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Results\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tuned Model\n",
    "tuned_model = xgb.XGBRFClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "              gamma=0, gpu_id=-1, importance_type=None,\n",
    "              interaction_constraints='', learning_rate=0.300000012,\n",
    "              max_delta_step=0, max_depth=6, min_child_weight=1,\n",
    "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
    "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
    "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
    "              subsample=1, tree_method='exact', validate_parameters=1,\n",
    "              verbosity=None)\n",
    "    \n",
    "# Lets fit the model\n",
    "htuned_model = tuned_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# Lets make predictions using the test dataset\n",
    "tuned_predictions = htuned_model.predict(X_test)\n",
    " \n",
    "# Lets check for accuracy\n",
    "accuracy = accuracy_score(tuned_predictions,y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculating F1 Scores, precision & recall\n",
    "precision = precision_recall_fscore_support(y_test, tuned_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
